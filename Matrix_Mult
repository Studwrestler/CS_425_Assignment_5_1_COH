                                                                                                                                                                                                          MatrixMult.c                                                                                                                                                                                                                            #include <mpi.h>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

#define N 5000

void generate_matrix(double *matrix) {
    for (int i = 0; i < N * N; i++) {
        matrix[i] = (double)rand() / RAND_MAX * 10.0;
    }
}

void serial_matrix_mult(double *A, double *B, double *C) {
printf("Rank 0: Starting serial multiplication...\n");
    fflush(stdout);
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            C[i * N + j] = 0.0;
            for (int k = 0; k < N; k++) {
                C[i * N + j] += A[i * N + k] * B[k * N + j];
            }
        }
    }
printf("Rank 0: Finished serial multiplication.\n");
    fflush(stdout);
}

int main(int argc, char *argv[]) {
    int rank, size;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    double *matrix = malloc(3 * N * N * sizeof(double));
    double *A = matrix;
    double *B = matrix + N * N;
    double *C = matrix + 2 * N * N;
    double *local_A = malloc((N / size) * N * sizeof(double));
    double *local_C = malloc((N / size) * N * sizeof(double));

    if (rank == 0) {
        srand(time(NULL));
        generate_matrix(A);
        generate_matrix(B);
    }

    MPI_Bcast(B, N * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);
    int rows_per_proc = N / size;
    MPI_Scatter(A, rows_per_proc * N, MPI_DOUBLE, local_A, rows_per_proc * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);

    clock_t parallel_start = clock();
    for (int i = 0; i < rows_per_proc; i++) {
        for (int j = 0; j < N; j++) {
            local_C[i * N + j] = 0.0;
            for (int k = 0; k < N; k++) {
                local_C[i * N + j] += local_A[i * N + k] * B[k * N + j];
            }
        }
    }
    clock_t parallel_end = clock();

    if (rank == 0) {
        C = malloc(N * N * sizeof(double));  // Allocate C only on rank 0
    }

    MPI_Gather(local_C, rows_per_proc * N, MPI_DOUBLE, C, rows_per_proc * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);
printf("Rank %d: Finished gathering results\n", rank);
fflush(stdout);
    if (rank == 0) {
        double *serial_C = malloc(N * N * sizeof(double));
        clock_t serial_start = clock();
        serial_matrix_mult(A, B, serial_C);
        clock_t serial_end = clock();

        double serial_time = (double)(serial_end - serial_start) / CLOCKS_PER_SEC;
        double parallel_time = (double)(parallel_end - parallel_start) / CLOCKS_PER_SEC;

        printf("Serial Execution Time: %f seconds\n", serial_time);
        printf("Parallel Execution Time: %f seconds\n", parallel_time);
        printf("Speedup: %f\n", serial_time / parallel_time);

        free(serial_C);
    }

    free(local_A);
    free(local_C);
    MPI_Barrier(MPI_COMM_WORLD);  // Ensure all processes finish before finalizing
    printf("Rank %d: Reached MPI_Finalize\n", rank);
    fflush(stdout);
    free(matrix);

    MPI_Finalize();
    return 0;
}
